"""–¢–µ—Å—Ç—ã –¥–ª—è ingest_service.py."""

from pathlib import Path
from unittest.mock import patch

import pytest

from src.config import Config
from src.ingest_service import (
    SUPPORTED_EXTENSIONS,
    _chunk_text,
    _delete_file_completely,
    _determine_categories,
    _extract_metadata,
    _process_file,
    check_and_cleanup_expired_confirmations,
    ingest_books,
)


@pytest.mark.asyncio
async def test_ingest_books_folder_not_found():
    """–¢–µ—Å—Ç: –ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    with pytest.raises(FileNotFoundError):
        await ingest_books("/nonexistent/folder")


@pytest.mark.asyncio
async def test_ingest_books_empty_folder(tmp_path):
    """–¢–µ—Å—Ç: –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞."""
    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    folder = tmp_path / "empty_books"
    folder.mkdir()

    # –î–æ–ª–∂–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
    await ingest_books(str(folder))


@pytest.mark.asyncio
async def test_ingest_books_with_mock_files(tmp_path):
    """–¢–µ—Å—Ç: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º —á—Ç–µ–Ω–∏–µ–º —Ñ–∞–π–ª–æ–≤."""
    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
    folder = tmp_path / "books"
    folder.mkdir()

    # –°–æ–∑–¥–∞—ë–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –≤ –∏–º–µ–Ω–∏
    # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –≤—ã–∑–æ–≤–∞ LLM –∏ –¥–µ–ª–∞–µ—Ç —Ç–µ—Å—Ç –±—ã—Å—Ç—Ä–µ–µ
    book1_content = (
        "–≠—Ç–∞ –∫–Ω–∏–≥–∞ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞, "
        "–æ —Ç–æ–º, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–æ–∑–≥ –∏ –∫–∞–∫ –ª—é–¥–∏ –ø—Ä–∏–Ω–∏–º–∞—é—Ç —Ä–µ—à–µ–Ω–∏—è. "
        "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—è ‚Äî —ç—Ç–æ –Ω–∞—É–∫–∞ –æ –ø—Å–∏—Ö–∏–∫–µ –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞. "
        "–û–Ω–∞ –∏–∑—É—á–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å—ã –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è, –º—ã—à–ª–µ–Ω–∏—è, –ø–∞–º—è—Ç–∏, —ç–º–æ—Ü–∏–π. "
    ) * 200  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —á–∞–Ω–∫–æ–≤ (–º–∏–Ω–∏–º—É–º 2000+ —Å–∏–º–≤–æ–ª–æ–≤)

    book2_content = (
        "–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ ‚Äî —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ-—Å–±—ã—Ç–æ–≤–æ–π "
        "–¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª–∏ —á–µ—Ä–µ–∑ "
        "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π. –í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –±–∏–∑–Ω–µ—Å–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ "
        "–∏–≥—Ä–∞–µ—Ç –∫–ª—é—á–µ–≤—É—é —Ä–æ–ª—å –≤ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤. "
    ) * 200  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —á–∞–Ω–∫–æ–≤

    # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –≤ –∏–º–µ–Ω–∏ (—á—Ç–æ–±—ã –Ω–µ –≤—ã–∑—ã–≤–∞—Ç—å LLM)
    (folder / "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è (–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è).txt").write_text(
        book1_content, encoding="utf-8"
    )
    (folder / "–û—Å–Ω–æ–≤—ã –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞ (–±–∏–∑–Ω–µ—Å, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥).txt").write_text(
        book2_content, encoding="utf-8"
    )

    # –ú–æ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Ä–æ–≥–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (embeddings –∏ FAISS)
    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–ª—å–Ω–æ–µ
    with (
        patch("src.ingest_service._create_embeddings_batch") as mock_embeddings,
        patch("src.ingest_service._save_to_faiss") as mock_save,
    ):
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–∫–∏ –¥–ª—è embeddings
        mock_embeddings.return_value = [[0.0] * 1536] * 10  # Mock embeddings

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —Ñ–∞–π–ª–∞–º
        book_categories = {}

        # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –≤—ã–∑–æ–≤—ã _save_to_faiss –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        def save_to_faiss_side_effect(*args, **kwargs):
            """–ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–∑–æ–≤ _save_to_faiss –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
            # _save_to_faiss(embeddings, chunks, metadata, file_path, file_hash, file_index)
            if len(args) >= 4:
                metadata = args[2]  # metadata - —Ç—Ä–µ—Ç–∏–π –∞—Ä–≥—É–º–µ–Ω—Ç
                file_path = args[3]  # file_path - —á–µ—Ç–≤–µ—Ä—Ç—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç
                file_name = Path(file_path).name
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                if metadata and len(metadata) > 0:
                    # metadata - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                    first_meta = metadata[0]
                    categories = first_meta.get("topics", [])
                    book_categories[file_name] = categories
                    print(f"\nüìö –ö–Ω–∏–≥–∞: {file_name}")
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {categories}")

        mock_save.side_effect = save_to_faiss_side_effect

        # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é
        await ingest_books(str(folder))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏ –±—ã–ª–∏ –≤—ã–∑–≤–∞–Ω—ã
        assert mock_embeddings.called, "Embeddings –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω—ã"
        assert mock_save.called, "–î–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ FAISS"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–Ω–∏–≥–∏
        print("\n" + "=" * 60)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –ö–ù–ò–ì:")
        print("=" * 60)
        
        expected_categories = {
            "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è (–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è).txt": ["–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è"],
            "–û—Å–Ω–æ–≤—ã –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞ (–±–∏–∑–Ω–µ—Å, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥).txt": ["–±–∏–∑–Ω–µ—Å", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥"],
        }

        for file_name, expected_cats in expected_categories.items():
            actual_cats = book_categories.get(file_name, [])
            print(f"\nüìñ {file_name}")
            print(f"   –û–∂–∏–¥–∞–µ–º—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {expected_cats}")
            print(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {actual_cats}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            assert file_name in book_categories, f"–ö–Ω–∏–≥–∞ {file_name} –Ω–µ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞"
            assert set(actual_cats) == set(expected_cats), (
                f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è {file_name} –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: "
                f"–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_cats}, –ø–æ–ª—É—á–µ–Ω–æ {actual_cats}"
            )
            print(f"   ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")

        print("\n" + "=" * 60)
        print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–Ω–∏–≥: {len(book_categories)}")
        print("=" * 60)


@pytest.mark.asyncio
async def test_ingest_real_books_from_folder(tmp_path, monkeypatch):
    """–¢–µ—Å—Ç: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ books (–µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç).
    
    –≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ books –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç,
    –≤ –∫–∞–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–Ω–∏ –±—ã–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.
    """
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ books (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è ai_library_bot)
    # –ü–∞–ø–∫–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ data/books —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞
    books_folder = Path("data/books")
    
    # –ï—Å–ª–∏ –ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    if not books_folder.exists() or not books_folder.is_dir():
        pytest.skip(f"–ü–∞–ø–∫–∞ {books_folder.absolute()} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç.")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
    book_files = [
        f for f in books_folder.iterdir()
        if f.is_file() and f.suffix.lower() in [".txt", ".pdf", ".epub", ".fb2"]
    ]
    
    if not book_files:
        pytest.skip(f"–í –ø–∞–ø–∫–µ {books_folder.absolute()} –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –∫–Ω–∏–≥. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç.")
    
    print(f"\n{'=' * 60}")
    print(f"–ù–ê–ô–î–ï–ù–û –§–ê–ô–õ–û–í –í –ü–ê–ü–ö–ï: {len(book_files)}")
    print(f"{'=' * 60}")
    for f in book_files:
        print(f"  - {f.name}")
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —Ñ–∞–π–ª–∞–º
    book_categories = {}
    
    # –ú–æ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Ä–æ–≥–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (embeddings –∏ FAISS)
    # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º create_confirmation_request –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    with (
        patch("src.ingest_service._create_embeddings_batch") as mock_embeddings,
        patch("src.ingest_service._save_to_faiss") as mock_save,
        patch("src.ingest_service.create_confirmation_request") as mock_create_confirmation,
    ):
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–∫–∏ –¥–ª—è embeddings
        mock_embeddings.return_value = [[0.0] * 1536] * 10  # Mock embeddings
        
        # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –≤—ã–∑–æ–≤—ã _save_to_faiss –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –≤ –∏–º–µ–Ω–∏)
        def save_to_faiss_side_effect(*args, **kwargs):
            """–ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–∑–æ–≤ _save_to_faiss –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
            if len(args) >= 4:
                metadata = args[2]  # metadata - —Ç—Ä–µ—Ç–∏–π –∞—Ä–≥—É–º–µ–Ω—Ç
                file_path = args[3]  # file_path - —á–µ—Ç–≤–µ—Ä—Ç—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç
                file_name = Path(file_path).name
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                if metadata and len(metadata) > 0:
                    first_meta = metadata[0]
                    categories = first_meta.get("topics", [])
                    book_categories[file_name] = categories
                    print(f"\nüìö –ö–Ω–∏–≥–∞ (–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞): {file_name}")
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {categories}")
        
        mock_save.side_effect = save_to_faiss_side_effect
        
        # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º create_confirmation_request –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ LLM
        def create_confirmation_side_effect(*args, **kwargs):
            """–ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
            # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ LLM —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            llm_categories = kwargs.get("categories_llm_recommendation", [])
            categories_from_filename = kwargs.get("categories_from_filename", [])
            file_path = kwargs.get("file_path")
            
            # –ï—Å–ª–∏ file_path –Ω–µ –≤ kwargs, –±–µ—Ä–µ–º –∏–∑ args
            if not file_path and args:
                file_path = args[0] if len(args) > 0 else None
            
            if file_path:
                file_name = Path(file_path).name
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ LLM, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                categories = llm_categories if llm_categories else categories_from_filename
                book_categories[file_name] = categories
                
                print(f"\nüìö –ö–Ω–∏–≥–∞ (—Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è): {file_name}")
                if llm_categories:
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (LLM): {llm_categories}")
                    print(f"   ‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
                elif categories_from_filename:
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞): {categories_from_filename}")
                else:
                    print(f"   ‚ö†Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º mock request_id
            import uuid
            return str(uuid.uuid4())
        
        mock_create_confirmation.side_effect = create_confirmation_side_effect
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É books
        await ingest_books(str(books_folder))
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    # –ß–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ FAISS –∏–Ω–¥–µ–∫—Å–∞
    from src.config import Config
    import pickle
    import faiss
    
    metadata_path = Config.FAISS_PATH.with_suffix(".metadata.pkl")
    if metadata_path.exists():
        try:
            print(f"\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –∏–Ω–¥–µ–∫—Å–∞: {metadata_path}")
            with open(metadata_path, "rb") as f:
                all_metadata = pickle.load(f)
            
            print(f"   –ù–∞–π–¥–µ–Ω–æ {len(all_metadata)} –∑–∞–ø–∏—Å–µ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ –∏–Ω–¥–µ–∫—Å–µ")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ —Ñ–∞–π–ª–∞–º –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            file_categories_from_index = {}
            for meta in all_metadata:
                file_path_str = meta.get("file_path", "")
                if file_path_str:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
                    file_name = Path(file_path_str).name
                    categories = meta.get("topics", [])
                    
                    # –ï—Å–ª–∏ –¥–ª—è —Ñ–∞–π–ª–∞ —É–∂–µ –µ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–±—ä–µ–¥–∏–Ω—è–µ–º (—É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã)
                    if file_name not in file_categories_from_index:
                        file_categories_from_index[file_name] = set()
                    if categories:
                        file_categories_from_index[file_name].update(categories)
            
            print(f"   –ù–∞–π–¥–µ–Ω–æ {len(file_categories_from_index)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ –≤ book_categories
            for file_name, categories_set in file_categories_from_index.items():
                if file_name not in book_categories:
                    categories_list = sorted(list(categories_set)) if categories_set else []
                    book_categories[file_name] = categories_list
                    print(f"\nüìö –ö–Ω–∏–≥–∞ (–∏–∑ –∏–Ω–¥–µ–∫—Å–∞): {file_name}")
                    if categories_list:
                        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {categories_list}")
                    else:
                        print(f"   ‚ö†Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã (—Ñ–∞–π–ª –±—ã–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –¥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π)")
                        
                        # –î–ª—è —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Ö —á–µ—Ä–µ–∑ LLM
                        file_path = books_folder / file_name
                        if file_path.exists():
                            print(f"   üîç –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —á–µ—Ä–µ–∑ LLM...")
                            try:
                                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                                from src.ingest_service import _read_txt_file, _read_pdf_file, _read_fb2_file, _read_epub_file
                                from src.category_parser import parse_categories_from_filename
                                from src.category_classifier import classify_book_category
                                
                                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∏ —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                                extension = file_path.suffix.lower()
                                if extension == ".txt":
                                    content = await _read_txt_file(file_path)
                                elif extension == ".pdf":
                                    content = await _read_pdf_file(file_path)
                                elif extension == ".epub":
                                    content = await _read_epub_file(file_path)
                                elif extension == ".fb2":
                                    content = await _read_fb2_file(file_path)
                                else:
                                    content = None
                                
                                if content:
                                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                                    book_title, categories_from_filename = parse_categories_from_filename(file_path)
                                    
                                    # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–µ—Ç –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM
                                    if not categories_from_filename:
                                        content_preview = content[:2000].strip() if content else None
                                        llm_result = await classify_book_category(book_title, content_preview)
                                        llm_categories = llm_result.get("topics", [])
                                        
                                        if llm_categories:
                                            book_categories[file_name] = llm_categories
                                            print(f"   ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã (LLM): {llm_categories}")
                                        else:
                                            print(f"   ‚ùå LLM –Ω–µ —Å–º–æ–≥ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
                                    else:
                                        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å—Ç—å –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                                        book_categories[file_name] = categories_from_filename
                                        print(f"   ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {categories_from_filename}")
                            except Exception as e:
                                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
        except Exception as e:
            print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            import traceback
            traceback.print_exc()
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\n{'=' * 60}")
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –†–ï–ê–õ–¨–ù–´–• –ö–ù–ò–ì:")
    print(f"{'=' * 60}")
    
    for file_name in sorted(book_categories.keys()):
        categories = book_categories[file_name]
        print(f"\nüìñ {file_name}")
        if categories:
            print(f"   ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(categories)}")
        else:
            print(f"   ‚ö†Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã (—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞)")
    
    print(f"\n{'=' * 60}")
    print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–Ω–∏–≥: {len(book_categories)}")
    print(f"–ö–Ω–∏–≥ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏: {sum(1 for cats in book_categories.values() if cats)}")
    print(f"–ö–Ω–∏–≥ –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {sum(1 for cats in book_categories.values() if not cats)}")
    print(f"{'=' * 60}\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–æ—Ç—è –±—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    assert len(book_categories) > 0, "–ù–∏ –æ–¥–Ω–∞ –∫–Ω–∏–≥–∞ –Ω–µ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞"


@pytest.mark.asyncio
async def test_process_file_too_large(tmp_path):
    """–¢–µ—Å—Ç: —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π."""
    # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª –±–æ–ª—å—à–µ 20MB (mock)
    large_file = tmp_path / "large.txt"
    large_file.write_text("x" * (21 * 1024 * 1024))  # 21 MB

    with pytest.raises(ValueError, match="—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π"):
        await _process_file(large_file)


@pytest.mark.asyncio
async def test_process_file_unsupported_format(tmp_path):
    """–¢–µ—Å—Ç: –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞."""
    unsupported_file = tmp_path / "book.doc"
    unsupported_file.write_text("content")

    with pytest.raises(ValueError, match="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"):
        await _process_file(unsupported_file)


def test_chunk_text():
    """–¢–µ—Å—Ç: —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏."""
    # –°–æ–∑–¥–∞—ë–º —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –¥–ª–∏–Ω—ã
    text = "Test sentence. " * 200  # ~3000 —Å–∏–º–≤–æ–ª–æ–≤

    chunks = _chunk_text(text, chunk_size=500, chunk_overlap=50)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —á–∞–Ω–∫–∏ —Å–æ–∑–¥–∞–Ω—ã
    assert len(chunks) > 0

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —á–∞–Ω–∫–∏ –±–æ–ª—å—à–µ MIN_CHUNK_SIZE
    for chunk in chunks:
        assert len(chunk.strip()) >= Config.MIN_CHUNK_SIZE

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —á–∞–Ω–∫–∏ –Ω–µ –ø—É—Å—Ç—ã–µ
    assert all(chunk.strip() for chunk in chunks)


def test_chunk_text_too_short():
    """–¢–µ—Å—Ç: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —á–∞–Ω–∫–æ–≤."""
    short_text = "Short text"  # –ú–µ–Ω—å—à–µ MIN_CHUNK_SIZE

    chunks = _chunk_text(short_text)

    # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, —Ç–∞–∫ –∫–∞–∫ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    assert len(chunks) == 0


def test_extract_metadata():
    """–¢–µ—Å—Ç: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
    file_path = Path("test_book.txt")
    content = "Some content"

    metadata = _extract_metadata(file_path, content)

    assert "title" in metadata
    assert "author" in metadata
    assert "file_path" in metadata
    assert "file_type" in metadata
    assert "topics" in metadata  # –ù–æ–≤–æ–µ –ø–æ–ª–µ
    assert metadata["file_type"] == ".txt"
    assert isinstance(metadata["topics"], list)


def test_extract_metadata_with_categories():
    """–¢–µ—Å—Ç: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    file_path = Path("–ö–Ω–∏–≥–∞ (–±–∏–∑–Ω–µ—Å, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥).txt")
    content = "Some content"

    metadata = _extract_metadata(file_path, content)

    assert metadata["title"] == "–ö–Ω–∏–≥–∞"
    assert "topics" in metadata
    assert "–±–∏–∑–Ω–µ—Å" in metadata["topics"]
    assert "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥" in metadata["topics"]


def test_supported_extensions():
    """–¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤."""
    assert ".txt" in SUPPORTED_EXTENSIONS
    assert ".pdf" in SUPPORTED_EXTENSIONS
    assert ".epub" in SUPPORTED_EXTENSIONS
    assert ".fb2" in SUPPORTED_EXTENSIONS
    assert ".doc" not in SUPPORTED_EXTENSIONS


@pytest.mark.asyncio
async def test_determine_categories_with_filename_categories(tmp_path):
    """–¢–µ—Å—Ç: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    file_path = tmp_path / "–ö–Ω–∏–≥–∞ (–±–∏–∑–Ω–µ—Å, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥).txt"
    file_path.write_text("content")

    categories = await _determine_categories(
        file_path, "–ö–Ω–∏–≥–∞", ["–±–∏–∑–Ω–µ—Å", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥"], content_preview=None
    )

    assert categories == ["–±–∏–∑–Ω–µ—Å", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥"]


@pytest.mark.asyncio
async def test_determine_categories_no_categories(tmp_path):
    """–¢–µ—Å—Ç: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    file_path = tmp_path / "–ö–Ω–∏–≥–∞.txt"
    file_path.write_text("content")
    content_preview = "–≠—Ç–∞ –∫–Ω–∏–≥–∞ –æ –±–∏–∑–Ω–µ—Å–µ –∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ."

    with patch("src.ingest_service.classify_book_category") as mock_classify:
        mock_classify.return_value = {
            "topics": ["–±–∏–∑–Ω–µ—Å"],
            "confidence": 0.95,
            "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ",
        }

        with patch("src.ingest_service.create_confirmation_request") as mock_create:
            categories = await _determine_categories(
                file_path, "–ö–Ω–∏–≥–∞", [], content_preview=content_preview
            )

            # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å None, —Ç–∞–∫ –∫–∞–∫ —Å–æ–∑–¥–∞–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            assert categories is None
            mock_create.assert_called_once()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ classify_book_category –±—ã–ª –≤—ã–∑–≤–∞–Ω —Å content_preview
            mock_classify.assert_called_once_with("–ö–Ω–∏–≥–∞", content_preview)


@pytest.mark.asyncio
async def test_delete_file_completely(tmp_path):
    """–¢–µ—Å—Ç: –ø–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞."""
    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    test_file = tmp_path / "test_book.txt"
    test_file.write_text("Test content")

    # –ú–æ–∫–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ –∏ confirmation_manager
    with (
        patch("src.ingest_service._remove_file_from_index") as mock_remove_index,
        patch("src.ingest_service.get_all_confirmations") as mock_get_confirmations,
        patch("src.ingest_service.delete_confirmation_request") as mock_delete_req,
    ):
        mock_get_confirmations.return_value = {}

        await _delete_file_completely(test_file)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —É–¥–∞–ª—ë–Ω
        assert not test_file.exists()
        mock_remove_index.assert_called_once()


@pytest.mark.asyncio
async def test_check_and_cleanup_expired_confirmations(tmp_path, monkeypatch):
    """–¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç—ë–∫—à–∏—Ö –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π."""
    from datetime import datetime, timedelta

    from src import config

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç 1 —á–∞—Å
    monkeypatch.setattr(config.Config, "CONFIRMATION_TIMEOUT_HOURS", 1)

    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    test_file = tmp_path / "expired_book.txt"
    test_file.write_text("Test content")

    # –ú–æ–∫–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏
    with (
        patch("src.ingest_service.get_expired_requests") as mock_get_expired,
        patch("src.ingest_service.get_confirmation_request") as mock_get_request,
        patch("src.ingest_service.update_confirmation_status") as mock_update_status,
        patch("src.ingest_service._delete_file_completely") as mock_delete,
        patch("src.ingest_service.delete_confirmation_request") as mock_delete_req,
    ):
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–∫–∏
        mock_get_expired.return_value = ["req_123"]
        mock_get_request.return_value = {
            "request_id": "req_123",
            "file_path": str(test_file.absolute()),
            "book_title": "–¢–µ—Å—Ç–æ–≤–∞—è –∫–Ω–∏–≥–∞",
        }

        deleted_count = await check_and_cleanup_expired_confirmations()

        assert deleted_count == 1
        mock_update_status.assert_called_once_with("req_123", "timeout")
        mock_delete.assert_called_once()
        mock_delete_req.assert_called_once()
